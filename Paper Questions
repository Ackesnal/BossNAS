Q1:
These works are searched by multi-trial NAS methods [62, 91, 2, 88, 11, 47], which are computationally prohibitive (costing thousands of GPU days).
- What is multi-trail NAS methods?

Q2:
Recent weight-sharing NAS methods [6, 52, 4, 43] encode the entire search space as a weight-sharing supernet to avoid repetitive training of candidate networks, thus largely reducing the search cost.
- What is weight-sharing NAS methods?

Q3:
- What is unsupervised NAS?

Q4:
- One-shot learning for reduce training time?
